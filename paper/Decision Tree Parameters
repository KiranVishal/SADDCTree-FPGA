Decision Tree Classfier:

class sklearn.tree.DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2,
min_samples_leaf=1, min_weight_fraction_leaf=0.0,max_features=None, random_state=None, max_leaf_nodes=None,
min_impurity_split=1e-07, class_weight=None, presort=False)

Parameters :-

Criterion: string - The function to determine the quality of split. The defualt is "gini" for Gini impurity and "entropy" 
                    for the information gain.
            
Splitter: string - The stratergy to choose the split at each node. "Best" is to choose the best split and "random" for 
                   a random split.
                   
max_features: int, float, string or None - The actual number of features to look into while finding the split. Different
                                          data types have different effect. See Reference 1.
                                       
max_depth: int or None - This specifies the max depth of the tree. "None" goes down till all leaves become pure.

min_samples_split: int, float (default=2) - Minimum number of samples needed to create the split. 

min_samples_leaf: int, float (default =1) - Minimum number of samples to be a leaf node. 

max_leaf_node: int, or None - Maximum number of leaf nodes to which the tree will grow.

min_impurity_split : float (default=1e-7) - The min treshold to determine the node split.

resort : bool, (default=False) - To presort the data to speed up the training. Good for small and bad for larger data sets.

Reference :
1. http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier
2. https://en.wikipedia.org/wiki/Decision_tree_learning
